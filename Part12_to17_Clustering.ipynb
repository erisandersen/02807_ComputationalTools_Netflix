{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee99d646",
   "metadata": {},
   "source": [
    "# 12) Clustering Overview & Config\n",
    "Bu bölüm, Part 11'den sonraki **Clustering** adımlarını içerir. LSH/MinHash tarafından üretilmiş **imza tablolarını** (title + s1..sK) kullanarak **K-Means** ve **DBSCAN** ile kümeleme yapar; per-type ve combined (multi-view) akışları destekler.\n",
    "\n",
    "**Çıktılar** `out/part12_17_clustering/` dizinine yazılır:\n",
    "- `{type}_kmeans_k{K}.csv`, `{type}_kmeans_pca.png`\n",
    "- `{type}_dbscan_eps{E}_min{M}.csv`, `{type}_dbscan_pca.png`\n",
    "- `combined_*` çıktıları (çoklu görünüm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "K_CANDIDATES = [5, 8, 10, 12, 15]\n",
    "SCALE_FEATURES = True\n",
    "\n",
    "# DBSCAN süpürme grid'i (gerektiğinde değiştir)\n",
    "DBSCAN_EPS_GRID = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "DBSCAN_MIN_SAMPLES = [3, 5, 8]\n",
    "\n",
    "OUT_DIR = Path('out/part12_17_clustering')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# İmza dosyaları — mevcut değilse atlanır. Arkadaşınız 17 parçayı tamamladığında # buraya yeni satırlar ekleyebilirsiniz.\n",
    "SIGNATURE_FILES = [\n",
    "    ('title',       'outputs/signatures_title.csv'),\n",
    "    ('description', 'outputs/signatures_description.csv'),\n",
    "    ('cast',        'outputs/signatures_cast.csv'),\n",
    "    ('director',    'outputs/signatures_director.csv'),\n",
    "    ('country',     'outputs/signatures_country.csv'),\n",
    "    ('year',        'outputs/signatures_year.csv'),\n",
    "    ('rating',      'outputs/signatures_rating.csv'),\n",
    "    ('type',        'outputs/signatures_type.csv'),\n",
    "    # ('language',   'outputs/signatures_language.csv'),\n",
    "    # ('production', 'outputs/signatures_production.csv'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91355bd6",
   "metadata": {},
   "source": [
    "# 13) Yardımcı Fonksiyonlar (IO, Ölçekleme, Görselleştirme, Değerlendirme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_signatures(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'title' not in df.columns:\n",
    "        raise ValueError(f\"'title' column missing in {csv_path}\")\n",
    "    sig_cols = [c for c in df.columns if c.startswith('s')]\n",
    "    if not sig_cols:\n",
    "        raise ValueError(f\"No signature columns s1..sK in {csv_path}\")\n",
    "    return df[['title'] + sig_cols]\n",
    "\n",
    "def get_feature_matrix(df: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:\n",
    "    sig_cols = [c for c in df.columns if c.startswith('s')]\n",
    "    X = df[sig_cols].values\n",
    "    if SCALE_FEATURES:\n",
    "        X = StandardScaler(with_mean=False).fit_transform(X)\n",
    "    return X, sig_cols\n",
    "\n",
    "def pca_plot(X: np.ndarray, labels: np.ndarray, title: str, out_path: Path):\n",
    "    pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "    reduced = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.scatter(reduced[:,0], reduced[:,1], c=labels, s=10)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('PCA1'); plt.ylabel('PCA2')\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def preview_clusters(titles: pd.Series, labels: np.ndarray, per_cluster:int=3):\n",
    "    df_tmp = pd.DataFrame({'title': titles, 'cluster': labels})\n",
    "    for c in sorted(df_tmp['cluster'].unique()):\n",
    "        ex = df_tmp.loc[df_tmp.cluster==c, 'title'].head(per_cluster).to_list()\n",
    "        print(f\"  Cluster {c}: {ex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b09f9",
   "metadata": {},
   "source": [
    "# 14) K-Means (Per-Type)\n",
    "Her imza tipi için en iyi `k` değerini (silhouette) seçip K-Means uygular; sonuçları kaydeder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83af0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_summary = []\n",
    "for name, path in SIGNATURE_FILES:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(f\"[SKIP] {name}: {path} bulunamadı.\")\n",
    "        continue\n",
    "\n",
    "    df = load_signatures(str(p))\n",
    "    X, sig_cols = get_feature_matrix(df)\n",
    "\n",
    "    best = {'k': None, 'sil': -1, 'labels': None}\n",
    "    for k in K_CANDIDATES:\n",
    "        km = KMeans(n_clusters=k, n_init='auto', random_state=RANDOM_STATE)\n",
    "        labels = km.fit_predict(X)\n",
    "        uniq = np.unique(labels)\n",
    "        if len(uniq) < 2 or len(uniq) == len(labels):\n",
    "            continue\n",
    "        sil = silhouette_score(X, labels)\n",
    "        if sil > best['sil']:\n",
    "            best = {'k': k, 'sil': sil, 'labels': labels}\n",
    "\n",
    "    if best['k'] is None:\n",
    "        print(f\"[WARN] {name}: uygun k bulunamadı.\")\n",
    "        km_summary.append({'name': name, 'k': None, 'silhouette': None})\n",
    "        continue\n",
    "\n",
    "    out_df = df[['title']].copy(); out_df['cluster'] = best['labels']\n",
    "    out_csv = OUT_DIR / f\"{name}_kmeans_k{best['k']}.csv\"\n",
    "    out_df.to_csv(out_csv, index=False)\n",
    "\n",
    "    out_png = OUT_DIR / f\"{name}_kmeans_pca.png\"\n",
    "    pca_plot(X, best['labels'], f\"{name} K-Means (k={best['k']}, sil={best['sil']:.2f})\", out_png)\n",
    "\n",
    "    print(f\"[OK][K-Means] {name}: k={best['k']} sil={best['sil']:.3f} -> {out_csv.name}\")\n",
    "    preview_clusters(df['title'], best['labels'])\n",
    "    km_summary.append({'name': name, 'k': best['k'], 'silhouette': round(best['sil'],3)})\n",
    "\n",
    "pd.DataFrame(km_summary).to_csv(OUT_DIR / 'kmeans_summary.csv', index=False)\n",
    "print('\\nK-Means özet ->', OUT_DIR / 'kmeans_summary.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dae0f9",
   "metadata": {},
   "source": [
    "# 15) DBSCAN (Per-Type)\n",
    "EPS ve min_samples grid'i üzerinde süpürme yapar. Performansı kümelerin sayısı, gürültü oranı (label = -1) ve varsa silhouette (≥2 küme) ile raporlar. En iyi konfigürasyonu seçip kaydeder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_summary = []\n",
    "for name, path in SIGNATURE_FILES:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(f\"[SKIP] {name}: {path} bulunamadı.\")\n",
    "        continue\n",
    "\n",
    "    df = load_signatures(str(p))\n",
    "    X, sig_cols = get_feature_matrix(df)\n",
    "\n",
    "    best = {'eps': None, 'min': None, 'score': -np.inf, 'labels': None, 'k': None, 'noise': None}\n",
    "    # Basit skor: (küme sayısı >=2) ve (noise oranı düşük) ve (silhouette yüksekse avantaj)\n",
    "    for eps in DBSCAN_EPS_GRID:\n",
    "        for m in DBSCAN_MIN_SAMPLES:\n",
    "            db = DBSCAN(eps=eps, min_samples=m)\n",
    "            labels = db.fit_predict(X)\n",
    "            uniq = np.unique(labels)\n",
    "            k = len(uniq[uniq!=-1])  # noise hariç cluster sayısı\n",
    "            noise_ratio = (labels==-1).mean()\n",
    "            # Silhouette yalnızca 2+ küme ve tüm tekil olmayan durumda anlamlıdır\n",
    "            sil = None\n",
    "            try:\n",
    "                if k >= 2 and (labels!=-1).sum() > 2:\n",
    "                    sil = silhouette_score(X[labels!=-1], labels[labels!=-1])\n",
    "            except Exception:\n",
    "                sil = None\n",
    "            # basit bir skor fonksiyonu: küme sayısı ve silhouette lehine, noise aleyhine\n",
    "            score = (k * 0.5) + ((sil or 0) * 1.0) - (noise_ratio * 0.3)\n",
    "            if score > best['score']:\n",
    "                best = {'eps': eps, 'min': m, 'score': score, 'labels': labels,\n",
    "                        'k': k, 'noise': round(noise_ratio,3)}\n",
    "\n",
    "    labels = best['labels']\n",
    "    out_df = df[['title']].copy(); out_df['cluster'] = labels\n",
    "    out_csv = OUT_DIR / f\"{name}_dbscan_eps{best['eps']}_min{best['min']}.csv\"\n",
    "    out_df.to_csv(out_csv, index=False)\n",
    "\n",
    "    # PCA görsel\n",
    "    out_png = OUT_DIR / f\"{name}_dbscan_pca.png\"\n",
    "    pca_plot(X, labels, f\"{name} DBSCAN (eps={best['eps']}, min={best['min']}, k={best['k']}, noise={best['noise']})\", out_png)\n",
    "\n",
    "    print(f\"[OK][DBSCAN] {name}: eps={best['eps']} min={best['min']} k={best['k']} noise={best['noise']} -> {out_csv.name}\")\n",
    "    # Gürültü (-1) harici örnekler\n",
    "    if (labels!=-1).any():\n",
    "        preview_clusters(df['title'][labels!=-1], labels[labels!=-1])\n",
    "    db_summary.append({'name': name, 'eps': best['eps'], 'min_samples': best['min'], 'clusters': best['k'], 'noise_ratio': best['noise'], 'score': round(best['score'],3)})\n",
    "\n",
    "pd.DataFrame(db_summary).to_csv(OUT_DIR / 'dbscan_summary.csv', index=False)\n",
    "print('\\nDBSCAN özet ->', OUT_DIR / 'dbscan_summary.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48180372",
   "metadata": {},
   "source": [
    "# 16) Combined (Multi-View) Clustering — K-Means ve DBSCAN\n",
    "Birden çok imza tablosunu `title` üzerinde birleştirir; ardından K-Means ve DBSCAN uygular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "loaded = []\n",
    "for name, path in SIGNATURE_FILES:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        continue\n",
    "    df = load_signatures(str(p))\n",
    "    sig_cols = [c for c in df.columns if c.startswith('s')]\n",
    "    df = df.rename(columns={c: f\"{name}_{c}\" for c in sig_cols})\n",
    "    loaded.append(df)\n",
    "\n",
    "if len(loaded) >= 2:\n",
    "    merged = reduce(lambda l, r: pd.merge(l, r, on='title', how='inner'), loaded)\n",
    "    feat_cols = [c for c in merged.columns if c != 'title']\n",
    "    Xc = merged[feat_cols].values\n",
    "    if SCALE_FEATURES:\n",
    "        Xc = StandardScaler(with_mean=False).fit_transform(Xc)\n",
    "\n",
    "    # K-Means (best k)\n",
    "    best = {'k': None, 'sil': -1, 'labels': None}\n",
    "    for k in K_CANDIDATES:\n",
    "        km = KMeans(n_clusters=k, n_init='auto', random_state=RANDOM_STATE)\n",
    "        labels = km.fit_predict(Xc)\n",
    "        uniq = np.unique(labels)\n",
    "        if len(uniq) < 2 or len(uniq) == len(labels):\n",
    "            continue\n",
    "        sil = silhouette_score(Xc, labels)\n",
    "        if sil > best['sil']:\n",
    "            best = {'k': k, 'sil': sil, 'labels': labels}\n",
    "\n",
    "    if best['k'] is not None:\n",
    "        out_df = merged[['title']].copy(); out_df['cluster'] = best['labels']\n",
    "        out_csv = OUT_DIR / f\"combined_kmeans_k{best['k']}.csv\"\n",
    "        out_df.to_csv(out_csv, index=False)\n",
    "        out_png = OUT_DIR / f\"combined_kmeans_pca.png\"\n",
    "        pca_plot(Xc, best['labels'], f\"combined K-Means (k={best['k']}, sil={best['sil']:.2f})\", out_png)\n",
    "        print(f\"[OK][combined K-Means] k={best['k']} sil={best['sil']:.3f} -> {out_csv.name}\")\n",
    "\n",
    "    # DBSCAN combined (grid sweep)\n",
    "    best_db = {'eps': None, 'min': None, 'score': -np.inf, 'labels': None, 'k': None, 'noise': None}\n",
    "    for eps in DBSCAN_EPS_GRID:\n",
    "        for m in DBSCAN_MIN_SAMPLES:\n",
    "            db = DBSCAN(eps=eps, min_samples=m)\n",
    "            labels = db.fit_predict(Xc)\n",
    "            uniq = np.unique(labels)\n",
    "            k = len(uniq[uniq!=-1])\n",
    "            noise_ratio = (labels==-1).mean()\n",
    "            sil = None\n",
    "            try:\n",
    "                if k >= 2 and (labels!=-1).sum() > 2:\n",
    "                    sil = silhouette_score(Xc[labels!=-1], labels[labels!=-1])\n",
    "            except Exception:\n",
    "                sil = None\n",
    "            score = (k * 0.5) + ((sil or 0) * 1.0) - (noise_ratio * 0.3)\n",
    "            if score > best_db['score']:\n",
    "                best_db = {'eps': eps, 'min': m, 'score': score, 'labels': labels,\n",
    "                           'k': k, 'noise': round(noise_ratio,3)}\n",
    "\n",
    "    labels = best_db['labels']\n",
    "    out_df = merged[['title']].copy(); out_df['cluster'] = labels\n",
    "    out_csv = OUT_DIR / f\"combined_dbscan_eps{best_db['eps']}_min{best_db['min']}.csv\"\n",
    "    out_df.to_csv(out_csv, index=False)\n",
    "    out_png = OUT_DIR / f\"combined_dbscan_pca.png\"\n",
    "    pca_plot(Xc, labels, f\"combined DBSCAN (eps={best_db['eps']}, min={best_db['min']}, k={best_db['k']}, noise={best_db['noise']})\", out_png)\n",
    "    print(f\"[OK][combined DBSCAN] eps={best_db['eps']} min={best_db['min']} k={best_db['k']} noise={best_db['noise']} -> {out_csv.name}\")\n",
    "else:\n",
    "    print('[INFO] combined: en az iki imza dosyası gerekli (şu an <2).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e5878",
   "metadata": {},
   "source": [
    "# 17) Raporlama & Sonraki Adımlar\n",
    "- `kmeans_summary.csv` ve `dbscan_summary.csv` dosyalarını raporda tablo olarak kullanın.\n",
    "- PCA görsellerinden örnekleri ekleyin.\n",
    "- Eğer ekip ek imza setleri (17 parçayı) push ederse `SIGNATURE_FILES` listesine ekleyip bu notebook'u tekrar çalıştırın.\n",
    "- (Opsiyonel) DBSCAN için k-distance grafiği, K-Means için Davies–Bouldin skoru ekleyebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31667a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Özetleri göster\n",
    "km_sum = OUT_DIR / 'kmeans_summary.csv'\n",
    "db_sum = OUT_DIR / 'dbscan_summary.csv'\n",
    "if km_sum.exists():\n",
    "    print('K-Means Summary:')\n",
    "    display(pd.read_csv(km_sum))\n",
    "else:\n",
    "    print('[INFO] kmeans_summary.csv yok')\n",
    "if db_sum.exists():\n",
    "    print('\\nDBSCAN Summary:')\n",
    "    display(pd.read_csv(db_sum))\n",
    "else:\n",
    "    print('[INFO] dbscan_summary.csv yok')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}