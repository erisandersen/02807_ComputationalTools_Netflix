{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b395b77",
   "metadata": {},
   "source": [
    "# Netflix recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d494f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import string, re\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from datasketch import  MinHash, MinHashLSH\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ea2d0",
   "metadata": {},
   "source": [
    "# Normalization of the Titles and Descriptions\n",
    "\n",
    "- Titles are lowercased, punctuation is removed, and parantheses stripped.\n",
    "- Descriptions are cleaned by lowercasing, removing punctuation, and collapsing whitespace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8343fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes sure the titles and descriptions are lowercased, removes punctuation.\n",
    "def normalize_title(title: str) -> str:\n",
    "    if pd.isna(title):\n",
    "        return \"\"\n",
    "    return re.sub(r\"\\(.*?\\)\", \"\", str(title)).lower().strip()\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab0247",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "We extract lists from:\n",
    "- **Genres**\n",
    "- **Director names**\n",
    "- **Cast names**\n",
    "- **Country**\n",
    "\n",
    "\n",
    "Each field becomes a list of normalized tokens, which we combine into a single `combined_features` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25d3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenizes director/cast/country, builds genre_list, and joins them in combined_features\n",
    "## Tokens are basically used so we can hash words to compare titles based on their hashing\n",
    "## Loads and prepocesses the data\n",
    "\n",
    "def tokenize_people(value: str) -> List[str]:\n",
    "      return [p.strip().lower() for p in str(value).split(\",\") if p and p.strip()]\n",
    "\n",
    "def tokenize_single(value: str) -> List[str]:\n",
    "    v = str(value).strip().lower()\n",
    "    return [v] if v else []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc39a5e",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "Here, we load the Netflix dataset after applying some preprocessing steps (normalizing titles and descriptions, tokenizing) and removing duplicate normalized titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4f1444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "      <th>title_normalized</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>director_tokens</th>\n",
       "      <th>cast_tokens</th>\n",
       "      <th>country_tokens</th>\n",
       "      <th>combined_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Dick Johnson Is Dead</td>\n",
       "      <td>Kirsten Johnson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>September 25, 2021</td>\n",
       "      <td>2020</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>As her father nears the end of his life, filmm...</td>\n",
       "      <td>dick johnson is dead</td>\n",
       "      <td>as her father nears the end of his life filmma...</td>\n",
       "      <td>[documentaries]</td>\n",
       "      <td>[kirsten johnson]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[united states]</td>\n",
       "      <td>[documentaries, kirsten johnson, united states]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Blood &amp; Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Mysteries</td>\n",
       "      <td>After crossing paths at a party, a Cape Town t...</td>\n",
       "      <td>blood &amp; water</td>\n",
       "      <td>after crossing paths at a party a cape town te...</td>\n",
       "      <td>[international tv shows, tv dramas, tv mysteries]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ama qamata, khosi ngema, gail mabalane, thaba...</td>\n",
       "      <td>[south africa]</td>\n",
       "      <td>[international tv shows, tv dramas, tv mysteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Ganglands</td>\n",
       "      <td>Julien Leclercq</td>\n",
       "      <td>Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Crime TV Shows, International TV Shows, TV Act...</td>\n",
       "      <td>To protect his family from a powerful drug lor...</td>\n",
       "      <td>ganglands</td>\n",
       "      <td>to protect his family from a powerful drug lor...</td>\n",
       "      <td>[crime tv shows, international tv shows, tv ac...</td>\n",
       "      <td>[julien leclercq]</td>\n",
       "      <td>[sami bouajila, tracy gotoas, samuel jouy, nab...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[crime tv shows, international tv shows, tv ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Jailbirds New Orleans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Docuseries, Reality TV</td>\n",
       "      <td>Feuds, flirtations and toilet talk go down amo...</td>\n",
       "      <td>jailbirds new orleans</td>\n",
       "      <td>feuds flirtations and toilet talk go down amon...</td>\n",
       "      <td>[docuseries, reality tv]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[docuseries, reality tv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Kota Factory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...</td>\n",
       "      <td>India</td>\n",
       "      <td>September 24, 2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, Romantic TV Shows, TV ...</td>\n",
       "      <td>In a city of coaching centers known to train I...</td>\n",
       "      <td>kota factory</td>\n",
       "      <td>in a city of coaching centers known to train i...</td>\n",
       "      <td>[international tv shows, romantic tv shows, tv...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mayur more, jitendra kumar, ranjan raj, alam ...</td>\n",
       "      <td>[india]</td>\n",
       "      <td>[international tv shows, romantic tv shows, tv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type                  title         director  \\\n",
       "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
       "1      s2  TV Show          Blood & Water              NaN   \n",
       "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
       "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
       "4      s5  TV Show           Kota Factory              NaN   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0                                                NaN  United States   \n",
       "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
       "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
       "3                                                NaN            NaN   \n",
       "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
       "\n",
       "           date_added  release_year rating   duration  \\\n",
       "0  September 25, 2021          2020  PG-13     90 min   \n",
       "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
       "2  September 24, 2021          2021  TV-MA   1 Season   \n",
       "3  September 24, 2021          2021  TV-MA   1 Season   \n",
       "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0                                      Documentaries   \n",
       "1    International TV Shows, TV Dramas, TV Mysteries   \n",
       "2  Crime TV Shows, International TV Shows, TV Act...   \n",
       "3                             Docuseries, Reality TV   \n",
       "4  International TV Shows, Romantic TV Shows, TV ...   \n",
       "\n",
       "                                         description       title_normalized  \\\n",
       "0  As her father nears the end of his life, filmm...   dick johnson is dead   \n",
       "1  After crossing paths at a party, a Cape Town t...          blood & water   \n",
       "2  To protect his family from a powerful drug lor...              ganglands   \n",
       "3  Feuds, flirtations and toilet talk go down amo...  jailbirds new orleans   \n",
       "4  In a city of coaching centers known to train I...           kota factory   \n",
       "\n",
       "                                   description_clean  \\\n",
       "0  as her father nears the end of his life filmma...   \n",
       "1  after crossing paths at a party a cape town te...   \n",
       "2  to protect his family from a powerful drug lor...   \n",
       "3  feuds flirtations and toilet talk go down amon...   \n",
       "4  in a city of coaching centers known to train i...   \n",
       "\n",
       "                                          genre_list    director_tokens  \\\n",
       "0                                    [documentaries]  [kirsten johnson]   \n",
       "1  [international tv shows, tv dramas, tv mysteries]                 []   \n",
       "2  [crime tv shows, international tv shows, tv ac...  [julien leclercq]   \n",
       "3                           [docuseries, reality tv]                 []   \n",
       "4  [international tv shows, romantic tv shows, tv...                 []   \n",
       "\n",
       "                                         cast_tokens   country_tokens  \\\n",
       "0                                                 []  [united states]   \n",
       "1  [ama qamata, khosi ngema, gail mabalane, thaba...   [south africa]   \n",
       "2  [sami bouajila, tracy gotoas, samuel jouy, nab...               []   \n",
       "3                                                 []               []   \n",
       "4  [mayur more, jitendra kumar, ranjan raj, alam ...          [india]   \n",
       "\n",
       "                                   combined_features  \n",
       "0    [documentaries, kirsten johnson, united states]  \n",
       "1  [international tv shows, tv dramas, tv mysteri...  \n",
       "2  [crime tv shows, international tv shows, tv ac...  \n",
       "3                           [docuseries, reality tv]  \n",
       "4  [international tv shows, romantic tv shows, tv...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_preprocess(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, encoding=\"latin1\", sep=\",\", quotechar='\"', engine=\"python\")\n",
    "\n",
    "    df[\"title_normalized\"] = df[\"title\"].fillna(\"\").apply(normalize_title)\n",
    "    df[\"description_clean\"] = df[\"description\"].fillna(\"\").apply(clean_text)\n",
    "\n",
    "    df = df.drop_duplicates(subset=\"title_normalized\").reset_index(drop=True)\n",
    "\n",
    "    df[\"genre_list\"] = df[\"listed_in\"].apply(\n",
    "        lambda x: [g.strip().lower() for g in str(x).split(\",\") if g.strip()]\n",
    "    )\n",
    "    df[\"director_tokens\"] = df[\"director\"].fillna(\"\").apply(tokenize_people)\n",
    "    df[\"cast_tokens\"] = df[\"cast\"].fillna(\"\").apply(tokenize_people)\n",
    "    df[\"country_tokens\"] = df[\"country\"].fillna(\"\").apply(tokenize_single)\n",
    "\n",
    "    df[\"combined_features\"] = (\n",
    "        df[\"genre_list\"] + df[\"director_tokens\"] + df[\"cast_tokens\"] + df[\"country_tokens\"]\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "df = load_and_preprocess(\"netflix_titles.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e901e5d",
   "metadata": {},
   "source": [
    "# Feature Matrix Construction\n",
    "\n",
    "We build two matrices that capture different information about each movie/TV series\n",
    "\n",
    "- **MLB** - We use MLB to one-hot encode the combined metadata:\n",
    "    \n",
    "    - Genres\n",
    "    - Directors\n",
    "    - Cast\n",
    "    - Country\n",
    "\n",
    "- **TF-IDF Matrix** - We use TF-IDF to identify the most characteristic words in each description, which are used later for MinHash and LSH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c1be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This creates a multi metadata matrix using MLB\n",
    "##And fits a TfIdf vectorizer\n",
    "def build_feature_matrices(df: pd.DataFrame):\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    combined_features_matrix = mlb.fit_transform(df[\"combined_features\"])\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 1),\n",
    "        min_df=3,\n",
    "        max_features=20000,\n",
    "        stop_words=\"english\"\n",
    "    )\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[\"description_clean\"])\n",
    "\n",
    "    return combined_features_matrix, tfidf_matrix, mlb, vectorizer\n",
    "\n",
    "combined_features_matrix, tfidf_matrix, mlb, vectorizer = build_feature_matrices(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae229b",
   "metadata": {},
   "source": [
    "# Sentence Emebdding Matrix\n",
    "\n",
    "We use sentence embedding matrix to capture semantic similarity, we encode each movie/TV series description using a SentenceTransformer model.\n",
    "\n",
    "These embeddings are later combined with metadata and MinHash similarities to create a stringer recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fdd55d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1875263a0a54de3b5cd373bac6f907f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Biggest change we use embedding matrix for description\n",
    "##The reson is that system embeddings allows synonyms which TfIdf doesnt do so we get a better description comparison\n",
    "## Also we keep both TfIdf and system embeddings because TfIdf will use the tokens for Minhash and LSH candidates\n",
    "## But system embeddings will be useful for similar words so we create a stronger recommendation system\n",
    "def build_embedding_matrix(df):\n",
    "    # default model we can change also this later\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    descriptions = df[\"description_clean\"].fillna(\"\").tolist()\n",
    "    \n",
    "    emb_matrix = model.encode(descriptions, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "    return emb_matrix\n",
    "\n",
    "embedding_matrix = build_embedding_matrix(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19c7cf",
   "metadata": {},
   "source": [
    "# Extracting Top TF-IDF Tokens\n",
    "For each item, we extract the tokens with the highest TF-IDF weight. Tokens represent the most important word from each description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72f4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This caches TfIdf vocabulary and extracts the top weighted tokens per row\n",
    "### Then hashes them with the active metadata label into Minhash signatures\n",
    "### Which then is used to built LSH index\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "def top_tfidf_tokens(row_idx: int, top_k: int = 40) -> List[str]:\n",
    "    start, end = tfidf_matrix.indptr[row_idx], tfidf_matrix.indptr[row_idx + 1]\n",
    "    indices = tfidf_matrix.indices[start:end]\n",
    "    data = tfidf_matrix.data[start:end]\n",
    "    if len(indices) == 0:\n",
    "        return []\n",
    "    order = np.argsort(data)\n",
    "    top = order[-top_k:]\n",
    "    return [feature_names[indices[i]] for i in top]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3418748a",
   "metadata": {},
   "source": [
    "# MinHash Signature Construction\n",
    "\n",
    "Each item is converted to a MinHash signature using:\n",
    "1. Top TF-IDF tokens\n",
    "2. Active metadata labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b49086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_minhash(row_idx: int, num_perm: int = 128):\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for token in top_tfidf_tokens(row_idx):\n",
    "        m.update(token.encode(\"utf8\"))\n",
    "    active_meta = combined_features_matrix[row_idx].nonzero()[0]\n",
    "    for col in active_meta:\n",
    "        label = mlb.classes_[col]\n",
    "        m.update(f\"meta:{label}\".encode(\"utf8\"))\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1403a99",
   "metadata": {},
   "source": [
    "# Building the LSH index\n",
    "\n",
    "We build an LSH index using MinHash signatures:\n",
    "\n",
    "- `num_perm = 128`\n",
    "- `threshold = 0.35`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c8b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_minhash_lsh(num_perm=128, threshold=0.35):\n",
    "    minhashes = {}\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "    for idx in range(len(df)):\n",
    "        m = create_minhash(idx, num_perm=num_perm)\n",
    "        minhashes[idx] = m\n",
    "        lsh.insert(str(idx), m)\n",
    "    return minhashes, lsh\n",
    "\n",
    "minhashes, lsh = build_minhash_lsh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe08803",
   "metadata": {},
   "source": [
    "# Candidate collection\n",
    "\n",
    "To find similar items for a target index:\n",
    "1. Query the LSH index for approximate neigbors\n",
    "2. If too few neighbors are found, we fill them by using:\n",
    "    - Top cosine-similar sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8efb4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Queries LSH for neighbors\n",
    "### If theres too few neighbors it increases the number of neighbors with system embedding neighbors so we have a good candidate pool\n",
    "def collect_candidates(idx: int, fallback_k: int = 200):\n",
    "    neighbors = [int(n) for n in lsh.query(minhashes[idx]) if int(n) != idx]\n",
    "    if len(neighbors) < fallback_k:\n",
    "        top_idx = np.argsort(\n",
    "            embedding_matrix @ embedding_matrix[idx]\n",
    "        )[-fallback_k:]\n",
    "        neighbors.extend(top_idx.tolist())\n",
    "    return np.unique(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9e46d",
   "metadata": {},
   "source": [
    "# Hybrid Distance Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0437c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This builds a distance matrix using cosine similarities and jaccard values\n",
    "##This matrix is used for clustering\n",
    "def build_distance_matrix(indices, w_desc=0.6, w_meta=0.4):\n",
    "    emb = embedding_matrix[indices]\n",
    "    meta = combined_features_matrix[indices]\n",
    "\n",
    "    desc_dist = pairwise_distances(emb, metric=\"cosine\") \n",
    "    meta_dist = pairwise_distances(meta, metric=\"cosine\")\n",
    "\n",
    "    \n",
    "    jac_sim = np.zeros((len(indices), len(indices)))\n",
    "    for i, idx_i in enumerate(indices):\n",
    "        for j, idx_j in enumerate(indices[i + 1:], start=i + 1):\n",
    "            sim = minhashes[idx_i].jaccard(minhashes[idx_j])\n",
    "            jac_sim[i, j] = jac_sim[j, i] = sim\n",
    "    jac_dist = 1 - jac_sim\n",
    "\n",
    "    hybrid_dist = 0.5 * (w_desc * desc_dist + w_meta * meta_dist) + 0.5 * jac_dist\n",
    "    return hybrid_dist\n",
    "\n",
    "sample_idx = np.random.choice(len(df), size=500, replace=False)\n",
    "distance_matrix = build_distance_matrix(sample_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55048c0b",
   "metadata": {},
   "source": [
    "# Similarity calculation\n",
    "\n",
    "We compute three types of similarities for a target:\n",
    "\n",
    "1. **Description similarity** using sentence embedding cosine similarity\n",
    "2. **Metadata similarity** using metadata cosine similarity\n",
    "3. **Jaccard similarity** from MinHash signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e084fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This computes the hybrid similarity list for a random target\n",
    "##  It uses system embedding cosine, metadata cosine and jaccard\n",
    "def compute_full_similarity(idx, top_k=100, w_desc=0.6, w_meta=0.4, w_jaccard=0.2):\n",
    "    \n",
    "    candidate_ids = [int(n) for n in lsh.query(minhashes[idx]) if int(n) != idx]\n",
    "\n",
    "    if len(candidate_ids) < top_k:\n",
    "        extra = np.argsort(\n",
    "            embedding_matrix @ embedding_matrix[idx]\n",
    "        )[-(top_k + 1):]\n",
    "        candidate_ids.extend(extra.tolist())\n",
    "\n",
    "    candidates = np.unique([c for c in candidate_ids if c != idx])\n",
    "    desc_sim = cosine_similarity(\n",
    "        embedding_matrix[idx].reshape(1, -1),\n",
    "        embedding_matrix[candidates]\n",
    "    ).flatten()\n",
    "    meta_sim = cosine_similarity(\n",
    "        combined_features_matrix[idx].reshape(1, -1),\n",
    "        combined_features_matrix[candidates]\n",
    "    ).flatten()\n",
    "    jac_sim = np.array([minhashes[idx].jaccard(minhashes[j]) for j in candidates])\n",
    "\n",
    "    hybrid = (1 - w_jaccard) * (w_desc * desc_sim + w_meta * meta_sim) + w_jaccard * jac_sim\n",
    "    ranked = candidates[np.argsort(hybrid)[::-1]]\n",
    "    scores = np.sort(hybrid)[::-1]\n",
    "    return list(zip(ranked, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d412b1",
   "metadata": {},
   "source": [
    "# Recommendation Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a531a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target           : \"Real Rob\"\n",
      "Target type      : \"TV Show\"\n",
      "Target genre(s)  : \"tv comedies\"\n",
      "\n",
      "Similar TV Shows:\n",
      "Name                                          Genres                                   Similarity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"Norm Macdonald Has a Show\"                   stand-up comedy & talk shows, tv come... 0.403\n",
      "\"Stand Up and Away! with Brian Regan\"         stand-up comedy & talk shows, tv come... 0.356\n",
      "\"Conan Without Borders\"                       docuseries, tv comedies                  0.341\n",
      "\"Chappelle's Show\"                            tv comedies                              0.335\n",
      "\"Middleditch & Schwartz\"                      tv comedies                              0.333\n",
      "\"Daniel Sloss: Live Shows\"                    stand-up comedy & talk shows, tv come... 0.330\n",
      "\"The Upshaws\"                                 tv comedies                              0.324\n",
      "\"The Joel McHale Show with Joel McHale\"       stand-up comedy & talk shows, tv come... 0.323\n",
      "\"Kevin Hart: Donât F**k This Up\"            docuseries                               0.323\n",
      "\"I Think You Should Leave with Tim Robinson\"  tv comedies                              0.321\n",
      "\n",
      "Cross-type suggestions:\n",
      "Name                                          Genres                                   Similarity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"Rob Schneider: Asian Momma, Mexican Kids\"    stand-up comedy                          0.459\n",
      "\"Kevin Hart: I'm a Grown Little Man\"          stand-up comedy                          0.337\n",
      "\"Dana Carvey: Straight White Male, 60\"        stand-up comedy                          0.294\n",
      "\"Jerry Seinfeld: I'm Telling You for the...\"  stand-up comedy                          0.287\n",
      "\"Bill Burr: You People Are All the Same\"      stand-up comedy                          0.287\n",
      "\"Jo Koy: Comin' In Hot\"                       stand-up comedy                          0.283\n",
      "\"Anjelah Johnson: Not Fancy\"                  stand-up comedy                          0.280\n",
      "\"Sam Jay: 3 In The Morning\"                   stand-up comedy                          0.280\n",
      "\"Mortified Nation\"                            documentaries                            0.278\n",
      "\"Louis C.K.: Hilarious\"                       movies                                   0.278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Finally this is the output\n",
    "## Same as before we define a target and compute the top 10 most similar (this might change depending on how you guys want)\n",
    "## Also computes a cross type so if a Tv series recommends a few movies (this can also change if u guys want)\n",
    "def print_recommendations(idx, recs=None, top_n=10):\n",
    "    if recs is None:\n",
    "        recs = compute_full_similarity(idx, top_k=top_n * 5)\n",
    "\n",
    "    target_title = df.loc[idx, \"title\"]\n",
    "    target_type = df.loc[idx, \"type\"] if \"type\" in df.columns else \"Unknown\"\n",
    "    target_genres = \", \".join(df.loc[idx, \"genre_list\"])\n",
    "\n",
    "    print(f'\\nTarget           : \"{target_title}\"')\n",
    "    print(f'Target type      : \"{target_type}\"')\n",
    "    print(f'Target genre(s)  : \"{target_genres}\"\\n')\n",
    "\n",
    "    same_type, other_type = [], []\n",
    "    for rec_idx, sim in recs:\n",
    "        entry = (\n",
    "            df.loc[rec_idx, \"title\"],\n",
    "            \", \".join(df.loc[rec_idx, \"genre_list\"]),\n",
    "            sim,\n",
    "        )\n",
    "        item_type = df.loc[rec_idx, \"type\"] if \"type\" in df.columns else \"Unknown\"\n",
    "        (same_type if item_type == target_type else other_type).append(entry)\n",
    "    \n",
    "    def truncate(text, max_len=40):\n",
    "        text = str(text)\n",
    "        return text if len(text) <= max_len else text[: max_len - 3] + \"...\"\n",
    "\n",
    "    def print_table(title, rows):\n",
    "        print(f\"{title}:\")\n",
    "        print(\"Name\".ljust(45), \"Genres\".ljust(40), \"Similarity\")\n",
    "        print(\"-\" * 100)\n",
    "        for name, genres, score in rows[:top_n]:\n",
    "            print(\n",
    "                f'\"{truncate(name, 42)}\"'.ljust(45),\n",
    "                truncate(genres, 40).ljust(40),\n",
    "                f\"{score:.3f}\",\n",
    "            )\n",
    "        print()\n",
    "\n",
    "    print_table(f\"Similar {target_type}s\", same_type)\n",
    "    print_table(\"Cross-type suggestions\", other_type)\n",
    "\n",
    "# example usage\n",
    "idx = np.random.randint(0, len(df)) ## this gives us a random target\n",
    "recommendations = {idx: compute_full_similarity(idx)}\n",
    "print_recommendations(idx, recommendations[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
