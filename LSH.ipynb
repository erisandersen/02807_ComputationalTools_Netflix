{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239ab997",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd81e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import re\n",
    "import mmh3\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string, re\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "df = pd.read_csv(\"netflix_titles.csv\", encoding=\"latin1\",sep=\",\",quotechar='\"',engine=\"python\")\n",
    "### TODO: ADD PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361c666",
   "metadata": {},
   "source": [
    "Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e77ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 8760 unique titles.\n"
     ]
    }
   ],
   "source": [
    "#%% Text cleaning\n",
    "def normalize_title(title):\n",
    "    if pd.isna(title):\n",
    "        return ''\n",
    "    return re.sub(r'\\(.*?\\)', '', title).lower().strip()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \" \", text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['title_normalized'] = df['title'].fillna('').apply(normalize_title)\n",
    "df['title_clean'] = df['title'].fillna('').apply(clean_text)\n",
    "df['description_clean'] = df['description'].fillna('').apply(clean_text)\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates(subset='title_normalized').reset_index(drop=True)\n",
    "df = df.drop_duplicates(subset='description_clean').reset_index(drop=True)\n",
    "print(f\"Data loaded: {len(df)} unique titles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc34bd1",
   "metadata": {},
   "source": [
    "Genre based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "553a748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process genres and countries\n",
    "df['genre_list'] = df['listed_in'].apply(lambda x: [g.strip() for g in x.split(',')] if pd.notnull(x) else [])\n",
    "df['combined_features'] = df['genre_list'] + df['country'].fillna('').apply(lambda x: [x])\n",
    "\n",
    "# One-hot encode genres + countries\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_country_matrix = mlb.fit_transform(df['combined_features'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8a6e4",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8288e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example top words for first description:\n",
      "kirsten inevitable johnson comical inventive nears stages filmmaker ways end both face death his help father them life as the\n"
     ]
    }
   ],
   "source": [
    "#%% TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['description_clean'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "rows, cols = tfidf_matrix.nonzero()\n",
    "tfidf_words = defaultdict(list)\n",
    "for r, c in zip(rows, cols):\n",
    "    tfidf_words[r].append((feature_names[c], tfidf_matrix[r, c]))\n",
    "\n",
    "top_n = 20\n",
    "def top_words(doc_idx, n=top_n):\n",
    "    words_scores = tfidf_words[doc_idx]\n",
    "    words_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    words = [w for w, _ in words_scores[:n]]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['description_tfidf'] = [top_words(i) for i in range(len(df))]\n",
    "print(\"\\nExample top words for first description:\")\n",
    "print(df.loc[0, 'description_tfidf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48226dc8",
   "metadata": {},
   "source": [
    "Shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e75247c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example shingles for first description:\n",
      "[['kirsten'], ['inevitable'], ['johnson'], ['comical'], ['inventive'], ['nears'], ['stages'], ['filmmaker'], ['ways'], ['end']]\n"
     ]
    }
   ],
   "source": [
    "#%% Shingling\n",
    "def shingle(q, text):\n",
    "    words = text.split()\n",
    "    return [words[i:i+q] for i in range(len(words)-q+1)]\n",
    "\n",
    "q = 1\n",
    "shingle_vector = [shingle(q, text) for text in df['description_tfidf']]\n",
    "print(\"\\nExample shingles for first description:\")\n",
    "print(shingle_vector[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97614627",
   "metadata": {},
   "source": [
    "MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85694ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "def create_minhash(text, genre_vec, num_perm=128):\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for word in set(text.split()):\n",
    "        m.update(word.encode('utf8'))\n",
    "    for i, val in enumerate(genre_vec):\n",
    "        if val == 1:\n",
    "            m.update(f'genre_{i}'.encode('utf8'))\n",
    "    return m\n",
    "\n",
    "\n",
    "minhashes = {}\n",
    "for idx, row in df.iterrows():\n",
    "    m = create_minhash(row['description_tfidf'], genre_country_matrix[idx])\n",
    "    minhashes[idx] = m\n",
    "\n",
    "\n",
    "lsh = MinHashLSH(threshold=0.35, num_perm=128)\n",
    "for idx, m in minhashes.items():\n",
    "    lsh.insert(str(idx), m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b8ee0",
   "metadata": {},
   "source": [
    "Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6e93139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 similar pairs (Jaccard ≥ 0.35):\n",
      "- InuYasha the Movie 4: Fire on the Mystic Island ↔ Inuyasha the Movie - L'isola del fuoco scarlatto | similarity: 1.00\n",
      "- Seven Souls in the Skull Castle: Season Bird ↔ Seven Souls in the Skull Castle: Season Wind | similarity: 0.95\n",
      "- Seven Souls in the Skull Castle: Season Moon Jogen ↔ Seven Souls in the Skull Castle: Season Moon Kagen | similarity: 0.92\n",
      "- Seven Souls in the Skull Castle: Season Moon Kagen ↔ Seven Souls in the Skull Castle: Season Wind | similarity: 0.91\n",
      "- Seven Souls in the Skull Castle: Season Moon Jogen ↔ Seven Souls in the Skull Castle: Season Wind | similarity: 0.90\n"
     ]
    }
   ],
   "source": [
    "#%% Compute Jaccard similarity for LSH pairs using datasketch MinHash\n",
    "\n",
    "def jaccard_datasketch(idx1, idx2):\n",
    "    m1 = minhashes[idx1]\n",
    "    m2 = minhashes[idx2]\n",
    "    return m1.jaccard(m2)\n",
    "\n",
    "similarities = []\n",
    "threshold = 0.35\n",
    "\n",
    "# Get LSH candidates for every item\n",
    "for i in range(len(df)):\n",
    "    neighbors = lsh.query(minhashes[i])\n",
    "    neighbors = [int(n) for n in neighbors if int(n) != i]\n",
    "\n",
    "    for j in neighbors:\n",
    "        # Avoid duplicates (i,j) and (j,i)\n",
    "        if i < j:\n",
    "            sim = jaccard_datasketch(i, j)\n",
    "            if sim >= threshold:\n",
    "                similarities.append((i, j, sim))\n",
    "\n",
    "# Sort by similarity\n",
    "similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(f\"\\nTop 5 similar pairs (Jaccard ≥ {threshold}):\")\n",
    "for i, j, sim in similarities[:5]:\n",
    "    print(f\"- {df.loc[i, 'title']} ↔ {df.loc[j, 'title']} | similarity: {sim:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef3cfb0",
   "metadata": {},
   "source": [
    "Build recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3416551c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final recommendations for 'Midnight Mass':\n",
      "- The Dirty Picture (similarity: 0.40)\n",
      "- Matichya Chuli (similarity: 0.36)\n",
      "- Thottappan (similarity: 0.35)\n"
     ]
    }
   ],
   "source": [
    "#%% Build recommendations and ensure all movies have top-N\n",
    "recommendations = defaultdict(list)\n",
    "\n",
    "# Fill from MinHash similarities first\n",
    "for i, j, sim in similarities:\n",
    "    if df.loc[i, 'title_normalized'] == df.loc[j, 'title_normalized']:\n",
    "        continue\n",
    "    recommendations[i].append((j, sim))\n",
    "    recommendations[j].append((i, sim))\n",
    "\n",
    "# Calculate cosine similarity for descriptions\n",
    "desc_similarity = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Calculate cosine similarity for genre + country\n",
    "genre_similarity = cosine_similarity(genre_country_matrix)\n",
    "\n",
    "# Combine both: You can adjust weights (e.g., 0.7 for descriptions, 0.3 for genres)\n",
    "cosine_sim = 0.7 * desc_similarity + 0.3 * genre_similarity\n",
    "\n",
    "top_n = 5\n",
    "for i in range(len(df)):\n",
    "    if len(recommendations[i]) < top_n:\n",
    "        sims = cosine_sim[i]\n",
    "        best_idx = np.argsort(sims)[::-1]\n",
    "        added = 0\n",
    "        for j in best_idx:\n",
    "            if i == j:\n",
    "                continue\n",
    "            if any(r[0] == j for r in recommendations[i]):\n",
    "                continue\n",
    "            recommendations[i].append((j, float(sims[j])))\n",
    "            added += 1\n",
    "            if added >= (top_n - len(recommendations[i])):\n",
    "                break\n",
    "\n",
    "# Truncate to top-N total\n",
    "for k, recs in recommendations.items():\n",
    "    recommendations[k] = sorted(recs, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "example_idx = np.random.randint(0, len(df))\n",
    "print(f\"\\nFinal recommendations for '{df.loc[5, 'title']}':\")\n",
    "for rec_idx, sim in recommendations[example_idx]:\n",
    "    print(f\"- {df.loc[rec_idx, 'title']} (similarity: {sim:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7893ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for: Dick Johnson Is Dead, ['Documentaries', 'United States']\n",
      " - Command and Control ['Documentaries', 'United States']\n",
      " - What the Health ['Documentaries', 'United States']\n",
      " - The Hurt Business ['Documentaries', 'Sports Movies', 'United States']\n",
      " - 13TH ['Documentaries', 'United States']\n",
      " - Fire in Paradise ['Documentaries', 'United States']\n",
      " - Paris Is Burning ['Classic Movies', 'Cult Movies', 'Documentaries', 'United States']\n",
      " - Quincy ['Documentaries', 'Music & Musicals', 'United States']\n",
      " - The Last Days ['Documentaries', 'United States']\n",
      " - Maddman: The Steve Madden Story ['Documentaries', 'United States']\n",
      " - Let It Fall: Los Angeles 1982-1992 ['Documentaries', 'United States']\n",
      " - Ariana grande: excuse me, i love you ['Documentaries', 'Music & Musicals', 'United States']\n",
      " - Take Your Pills ['Documentaries', 'United States']\n",
      " - De Palma ['Documentaries', 'United States']\n",
      " - Nature: Raising the Dinosaur Giant ['Documentaries', 'United States']\n",
      " - The Force ['Documentaries', 'United States']\n",
      " - Extremis ['Documentaries', 'United States']\n",
      " - Miss Americana ['Documentaries', 'Music & Musicals', 'United States']\n",
      " - Iron Cowboy: The Story of the 50.50.50 ['Documentaries', 'Sports Movies', 'United States']\n",
      " - Vikings Unearthed ['Documentaries', 'United States']\n",
      " - Ram Dass, Going Home ['Documentaries', 'Faith & Spirituality', 'United States']\n",
      " - Whose Streets? ['Documentaries', 'United States']\n",
      " - The Speed Cubers ['Documentaries', 'United States']\n",
      " - The B-Side: Elsa Dorfman's Portrait Photography ['Documentaries', 'United States']\n",
      " - Travis Scott: Look Mom I Can Fly ['Documentaries', 'Music & Musicals', 'United States']\n",
      " - Feminists: What Were They Thinking? ['Documentaries', 'LGBTQ Movies', 'United States']\n",
      " - Nazi Concentration Camps ['Classic Movies', 'Documentaries', 'United States']\n",
      " - I'll Sleep When I'm Dead ['Documentaries', 'Music & Musicals', 'United States']\n",
      " - After Porn Ends ['Documentaries', 'United States']\n",
      " - Father Soldier Son ['Documentaries', 'United States']\n",
      " - The Animal People ['Documentaries', 'United States']\n",
      " - The Redeemed and the Dominant: Fittest on Earth ['Documentaries', 'Sports Movies', 'United States']\n",
      " - Surviving R. Kelly: The Impact ['Documentaries', 'United States']\n",
      " - Mucho Mucho Amor: The Legend of Walter Mercado ['Documentaries', 'LGBTQ Movies', 'United States']\n",
      " - The Remix: Hip Hop X Fashion ['Documentaries', 'Music & Musicals', 'United States']\n",
      " - Enlighten Us ['Documentaries', 'United States']\n",
      " - Generation Iron 2 ['Documentaries', 'Sports Movies', 'United States']\n",
      " - We, the Marines ['Documentaries', 'International Movies', 'United States']\n",
      " - The C Word ['Documentaries', 'United States']\n",
      " - Hot Girls Wanted ['Documentaries', 'United States']\n",
      " - BLACKPINK: Light Up the Sky ['Documentaries', 'Music & Musicals', 'United States']\n",
      " - In Our Mothers' Gardens ['Documentaries', 'United States']\n",
      " - The Road to El Camino: Behind the Scenes of El Camino: A Breaking Bad Movie ['Documentaries', 'International Movies', 'United States']\n",
      " - Calum von Moger: Unbroken ['Documentaries', 'Sports Movies', 'United States']\n",
      " - LA 92 ['Documentaries', 'United States']\n",
      " - Seaspiracy ['Documentaries', 'United States']\n"
     ]
    }
   ],
   "source": [
    "# Change the index below to test a different title\n",
    "idx_query = 0\n",
    "\n",
    "query_minhash = create_minhash(df.loc[idx_query, 'description_clean'], genre_country_matrix[idx_query])\n",
    "results = lsh.query(query_minhash)\n",
    "\n",
    "print(f\"Recommendations for: {df.loc[idx_query, 'title']}, {df.loc[idx_query, 'combined_features']}\")\n",
    "for i in results:\n",
    "    i = int(i)\n",
    "    if i != idx_query:\n",
    "        print(\" -\", df.loc[i, 'title'],df.loc[i,'combined_features'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d36b95",
   "metadata": {},
   "source": [
    "Build Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a6d4b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.99113316, 0.97229944, ..., 0.86713563, 0.86172156,\n",
       "        0.96087197],\n",
       "       [0.99113316, 0.        , 0.92269044, ..., 0.99766908, 1.        ,\n",
       "        1.        ],\n",
       "       [0.97229944, 0.92269044, 0.        , ..., 0.99004171, 0.98954891,\n",
       "        0.93452146],\n",
       "       ...,\n",
       "       [0.86713563, 0.99766908, 0.99004171, ..., 0.        , 0.78204466,\n",
       "        0.99437644],\n",
       "       [0.86172156, 1.        , 0.98954891, ..., 0.78204466, 0.        ,\n",
       "        0.99498107],\n",
       "       [0.96087197, 1.        , 0.93452146, ..., 0.99437644, 0.99498107,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = cosine_sim\n",
    "\n",
    "distance_matrix = 1 - similarity_matrix ## this should be used for the clustering\n",
    "distance_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9ce8e",
   "metadata": {},
   "source": [
    "Output for a target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caf0f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target           : \"Midnight Mass\"\n",
      "Target type      : \"TV Show\"\n",
      "Target genre(s)  : \"TV Dramas, TV Horror, TV Mysteries\"\n",
      "\n",
      "Similar TV Shows:\n",
      "Name                                          Genres                              Similarity\n",
      "------------------------------------------------------------------------------------------\n",
      "\"Goodnight DJ 1\"                              International TV Shows, TV Dramas, TV Horror 0.242\n",
      "\"Brand New Cherry Flavor\"                     TV Dramas, TV Horror, TV Mysteries  0.240\n",
      "\"The Originals\"                               TV Dramas, TV Horror, TV Mysteries  0.239\n"
     ]
    }
   ],
   "source": [
    "target_index = 5 ## Changing the index changes the target \n",
    "\n",
    "target_title = df.loc[target_index, 'title']\n",
    "target_genres= ', '.join(df.loc[target_index, 'genre_list'])\n",
    "target_type = df.loc[target_index, 'type'] if 'type' in df.columns else \"Unknown\"\n",
    "\n",
    "print(f'\\nTarget           : \"{target_title}\"')\n",
    "print(f'Target type      : \"{target_type}\"')\n",
    "print(f'Target genre(s)  : \"{target_genres}\"\\n')\n",
    "\n",
    "same_type = []\n",
    "other_type = []\n",
    "\n",
    "for rec_idx, sim in recommendations[target_index]:\n",
    "    item_type = df.loc[rec_idx, 'type'] if 'type' in df.columns else \"Unknown\"\n",
    "    entry = (\n",
    "        df.loc[rec_idx, 'title'],\n",
    "        \", \".join(df.loc[rec_idx, 'genre_list']),\n",
    "        sim\n",
    "    )\n",
    "    if item_type == target_type:\n",
    "        same_type.append(entry)\n",
    "    else:\n",
    "        other_type.append(entry)\n",
    "\n",
    "\n",
    "print(f'Similar {target_type}s:')\n",
    "print(\"Name\".ljust(45), \"Genres\".ljust(35), \"Similarity\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for title, genres, sim in same_type:\n",
    "    print(f'\"{title}\"'.ljust(45), f'{genres}'.ljust(35), f\"{sim:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
